# coding:utf-8
import itertools
import math
import traceback
from datetime import datetime
from pathlib import Path
import time

import torch
from torch import nn, optim, cuda
from torch.backends import cudnn
from torch.nn import init

from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from utils.log_utils import LossLogger

from .dataset import collate_fn
from .loss import SSDLoss
from .ssd import SSD


def exception_handler(train_func):
    """ å¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿçš„å¼‚å¸¸å¹¶ä¿å­˜æ¨¡å‹ """
    def wrapper(train_pipeline, *args, **kwargs):
        try:
            return train_func(train_pipeline, *args, **kwargs)
        except BaseException as e:
            if not isinstance(e, KeyboardInterrupt):
                traceback.print_exc()

            train_pipeline.save()
            exit()

    return wrapper


class TrainPipeline:
    """ è®­ç»ƒ SSD æ¨¡å‹ """

    def __init__(self, dataset: Dataset, vgg_path: str = None, ssd_path: str = None,
                 lr=0.001, momentum=0.9, weight_decay=5e-4, lr_steps=(40000, 50000, 60000),
                 batch_size=16, num_workers=0, start_iter=0, max_iter=60000, save_frequency=2000,
                 use_gpu=True, save_dir='model', log_file: str = None, log_dir='log', **config):
        """
        Parameters
        ----------
        dataset: Dataset
            è®­ç»ƒæ•°æ®é›†

        vgg_path: str
            é¢„è®­ç»ƒçš„ VGG16 æ¨¡å‹æ–‡ä»¶è·¯å¾„

        ssd_path: Union[str, None]
            SSD æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§é€‰æ‹©:
            * å¦‚æœä¸ä¸º `None`ï¼Œå°†ä½¿ç”¨æ¨¡å‹æ–‡ä»¶ä¸­çš„å‚æ•°åˆå§‹åŒ– `SSD`
            * å¦‚æœä¸º `None`ï¼Œå°†ä½¿ç”¨ `init.xavier` æ–¹æ³•åˆå§‹åŒ– VGG16 ä¹‹åçš„å·ç§¯å±‚å‚æ•°

        lr: float
            å­¦ä¹ ç‡

        momentum: float
            å†²é‡

        weight_decay: float
            æƒé‡è¡°å‡

        lr_steps: Tuple[int]
            å­¦ä¹ ç‡é€€ç«çš„èŠ‚ç‚¹

        batch_size: int
            è®­ç»ƒé›† batch å¤§å°

        num_workers: int
            åŠ è½½æ•°æ®çš„çº¿ç¨‹æ•°ï¼ŒWindows ç³»ç»Ÿå¿…é¡»ä¸º 0

        start_iter: int
            SSD æ¨¡å‹æ–‡ä»¶åŒ…å«çš„å‚æ•°æ˜¯è®­ç»ƒäº†å¤šå°‘æ¬¡çš„ç»“æœ

        max_iter: int
            æœ€å¤šè¿­ä»£å¤šå°‘æ¬¡

        save_frequency: int
            è¿­ä»£å¤šå°‘æ¬¡ä¿å­˜ä¸€æ¬¡æ¨¡å‹

        use_gpu: bool
            æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒ

        save_dir: str
            ä¿å­˜ SSD æ¨¡å‹çš„æ–‡ä»¶å¤¹

        log_file: str
            è®­ç»ƒæŸå¤±æ•°æ®å†å²è®°å½•æ–‡ä»¶ï¼Œè¦æ±‚æ˜¯ json æ–‡ä»¶

        save_dir: str
            è®­ç»ƒæŸå¤±æ•°æ®ä¿å­˜çš„æ–‡ä»¶å¤¹

        **config:
            å…ˆéªŒæ¡†ç”Ÿæˆã€å…ˆéªŒæ¡†å’Œè¾¹ç•Œæ¡†åŒ¹é…ä»¥åŠ NMS ç®—æ³•çš„é…ç½®
        """
        self.config = {
            # é€šç”¨é…ç½®
            'n_classes': 21,
            'variance': (0.1, 0.2),

            # å…ˆéªŒæ¡†ç”Ÿæˆé…ç½®
            "image_size": 300,
            'steps': [8, 16, 32, 64, 100, 300],
            'feature_maps': [38, 19, 10, 5, 3, 1],
            'min_sizes': [30, 60, 111, 162, 213, 264],
            'max_sizes': [60, 111, 162, 213, 264, 315],
            'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],

            # NMS é…ç½®
            'top_k': 200,
            'nms_thresh': 0.45,
            'conf_thresh': 0.01,

            # å…ˆéªŒæ¡†å’Œè¾¹ç•Œæ¡†åŒ¹é…é…ç½®
            'overlap_thresh': 0.5,

            # å›°éš¾æ ·æœ¬æŒ–æ˜é…ç½®
            'neg_pos_ratio': 3,
        }
        self.config.update(config)

        self.dataset = dataset
        self.save_dir = Path(save_dir)
        self.use_gpu = use_gpu
        self.save_frequency = save_frequency
        self.batch_size = batch_size
        self.num_workers = num_workers

        if use_gpu and cuda.is_available():
            self.device = torch.device('cuda')
            cudnn.benchmark = True
        else:
            self.device = torch.device('cpu')

        # ä¸€ä¸ª epoch æœ‰å¤šå°‘ä¸ª batch
        self.n_batches = math.ceil(len(self.dataset)/self.batch_size)

        # åˆ›å»ºæ¨¡å‹
        self.model = SSD(**self.config).to(self.device)

        # è¿­ä»£æ¬¡æ•°
        self.current_iter = start_iter
        self.start_iter = start_iter
        self.max_iter = max_iter

        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.critorion = SSDLoss(**self.config)
        self.optimizer = optim.SGD(
            [{"params": self.model.parameters(), 'initial_lr': lr}],
            lr, momentum, weight_decay=weight_decay
        )
        self.lr_schedule = optim.lr_scheduler.MultiStepLR(
            self.optimizer, lr_steps, 0.1, last_epoch=start_iter)

        # è®­ç»ƒæŸå¤±è®°å½•å™¨
        self.logger = LossLogger(self.n_batches, log_file, log_dir)

        # åˆå§‹åŒ–æ¨¡å‹
        if ssd_path:
            self.model.load_state_dict(torch.load(ssd_path))
            print('ğŸ§ª æˆåŠŸè½½å…¥ SSD æ¨¡å‹ï¼š' + ssd_path)
        elif vgg_path:
            self.model.vgg.load_state_dict(torch.load(vgg_path))
            self.model.extras.apply(self.xavier)
            self.model.confs.apply(self.xavier)
            self.model.locs.apply(self.xavier)
            print('ğŸ§ª æˆåŠŸè½½å…¥ VGG16 æ¨¡å‹ï¼š' + vgg_path)
        else:
            raise ValueError("å¿…é¡»æŒ‡å®šé¢„è®­ç»ƒçš„ VGG16 æ¨¡å‹æ–‡ä»¶è·¯å¾„")

    def save(self):
        """ ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒæŸå¤±æ•°æ® """
        self.save_dir.mkdir(exist_ok=True, parents=True)

        # ä¿å­˜æ¨¡å‹
        self.model.eval()
        path = self.save_dir/f'SSD_{self.current_iter+1}.pth'
        torch.save(self.model.state_dict(), path)

        # ä¿å­˜è®­ç»ƒæŸå¤±æ•°æ®
        self.logger.save(f'train_losses_{self.current_iter+1}')

        print(f'\nğŸ‰ å·²å°†å½“å‰æ¨¡å‹ä¿å­˜åˆ° {path.absolute()}\n')

    @staticmethod
    def xavier(module):
        """ ä½¿ç”¨ xavier æ–¹æ³•åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•° """
        if not isinstance(module, nn.Conv2d):
            return

        init.xavier_uniform_(module.weight)
        init.constant_(module.bias, 0)

    @exception_handler
    def train(self):
        """ è®­ç»ƒæ¨¡å‹ """
        t = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))
        self.save_dir = self.save_dir/t
        self.logger.save_dir = self.logger.save_dir/t

        data_loader = DataLoader(
            self.dataset,
            self.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            num_workers=self.num_workers,
            pin_memory=True
        )
        # æ— ç©·è¿­ä»£å™¨
        data_iter = itertools.cycle(data_loader)

        bar_format = '{desc}{n_fmt:>4s}/{total_fmt:<4s}|{bar}|{postfix}'
        print('ğŸš€ å¼€å§‹è®­ç»ƒï¼')

        with tqdm(total=self.n_batches, bar_format=bar_format) as bar:
            self.model.train()
            start_time = datetime.now()

            for i in range(self.start_iter, self.max_iter):
                self.current_iter = i
                if i > self.start_iter and (i-self.start_iter) % self.n_batches == 0:
                    start_time = datetime.now()
                    print('')
                    bar.reset()

                e = math.floor((i-self.start_iter)/self.n_batches) + 1
                bar.set_description(f"\33[36mğŸŒŒ Epoch {e:5d}")

                # å–å‡ºæ•°æ®
                images, targets = next(data_iter)

                # é¢„æµ‹è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦å’Œå…ˆéªŒæ¡†
                pred = self.model(images.to(self.device))

                # è®¡ç®—æŸå¤±å¹¶å°†è¯¯å·®åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loc_loss, conf_loss = self.critorion(pred, targets)
                loss = loc_loss + conf_loss  # type:torch.Tensor
                loss.backward()
                self.optimizer.step()
                self.lr_schedule.step()

                cost_time = datetime.now() - start_time
                bar.set_postfix_str(
                    f'loss: {loss.item():.3f}, loc_loss: {loc_loss.item():.3f}, conf_loss: {conf_loss.item():.3f}, æ‰§è¡Œæ—¶é—´: {cost_time}\33[0m')
                bar.update()

                # æ›´æ–°æŸå¤±
                self.logger.update(loc_loss.item(), conf_loss.item())

                # å®šæœŸä¿å­˜æ¨¡å‹
                if i > self.start_iter and (i-self.start_iter) % self.save_frequency == 0:
                    self.save()

        self.save()
